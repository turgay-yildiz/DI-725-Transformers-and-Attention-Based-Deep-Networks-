{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:06.475165Z",
     "iopub.status.busy": "2025-05-13T02:09:06.474254Z",
     "iopub.status.idle": "2025-05-13T02:09:06.478799Z",
     "shell.execute_reply": "2025-05-13T02:09:06.478029Z",
     "shell.execute_reply.started": "2025-05-13T02:09:06.475136Z"
    },
    "id": "UHflqji43qh9"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T06:47:50.075028Z",
     "iopub.status.busy": "2025-05-02T06:47:50.074537Z",
     "iopub.status.idle": "2025-05-02T06:47:50.080173Z",
     "shell.execute_reply": "2025-05-02T06:47:50.07928Z",
     "shell.execute_reply.started": "2025-05-02T06:47:50.075003Z"
    },
    "id": "UN1gBnmQ4LAj",
    "outputId": "a6ca43c0-0430-484f-bc05-665711eea867"
   },
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h1 style=\"color:red;\">DI-725 : Transformers and Attention-Based Deep Networks</h1>\n",
    "  <h2 style=\"color:red;\">Final Project : Phase - 2</h2>\n",
    "  <br><br>\n",
    "  <h4 style=\"color:red;\">Turgay Yıldız</h4>\n",
    "  <br>\n",
    "  <h4 style=\"color:red;\">Graduate School of Informatics, Middle East Technical University (METU)</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T06:47:11.957103Z",
     "iopub.status.busy": "2025-05-02T06:47:11.95643Z",
     "iopub.status.idle": "2025-05-02T06:47:11.961543Z",
     "shell.execute_reply": "2025-05-02T06:47:11.960914Z",
     "shell.execute_reply.started": "2025-05-02T06:47:11.95708Z"
    },
    "id": "lM_sMe2M4uhH",
    "outputId": "fb87cfd2-03e6-4c9e-b395-064dac894355"
   },
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\">Fetch big_vision code and install dependencies</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:07.365712Z",
     "iopub.status.busy": "2025-05-13T02:09:07.365099Z",
     "iopub.status.idle": "2025-05-13T02:09:14.332791Z",
     "shell.execute_reply": "2025-05-13T02:09:14.332049Z",
     "shell.execute_reply.started": "2025-05-13T02:09:07.365686Z"
    },
    "id": "0EJMa-2k-UuK",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "!pip install evaluate\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:14.574116Z",
     "iopub.status.busy": "2025-05-13T02:09:14.573805Z",
     "iopub.status.idle": "2025-05-13T02:09:14.579080Z",
     "shell.execute_reply": "2025-05-13T02:09:14.578330Z",
     "shell.execute_reply.started": "2025-05-13T02:09:14.574089Z"
    },
    "id": "JlP2ZBh3-UoM"
   },
   "outputs": [],
   "source": [
    "# Fetch big_vision repository if python doesn't know about it and install\n",
    "# dependencies needed for this notebook.\n",
    "if not os.path.exists(\"big_vision_repo\"):\n",
    "  !git clone --quiet --branch=main --depth=1 \\\n",
    "     https://github.com/google-research/big_vision big_vision_repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:14.782225Z",
     "iopub.status.busy": "2025-05-13T02:09:14.782034Z",
     "iopub.status.idle": "2025-05-13T02:09:14.785848Z",
     "shell.execute_reply": "2025-05-13T02:09:14.785131Z",
     "shell.execute_reply.started": "2025-05-13T02:09:14.782210Z"
    },
    "id": "hjlUuo-E-UlP"
   },
   "outputs": [],
   "source": [
    "# Append big_vision code to python import path\n",
    "if \"big_vision_repo\" not in sys.path:\n",
    "  sys.path.append(\"big_vision_repo\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:14.986496Z",
     "iopub.status.busy": "2025-05-13T02:09:14.986240Z",
     "iopub.status.idle": "2025-05-13T02:09:17.882450Z",
     "shell.execute_reply": "2025-05-13T02:09:17.881669Z",
     "shell.execute_reply.started": "2025-05-13T02:09:14.986478Z"
    },
    "id": "xAKDOz6_-UKV",
    "outputId": "44fb86ee-55b1-41e1-bf4e-69c79ab198dd"
   },
   "outputs": [],
   "source": [
    "# Install missing dependencies. Assume jax~=0.4.25 with GPU available.\n",
    "!pip3 install -q \"overrides\" \"ml_collections\" \"einops~=0.7\" \"sentencepiece\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHH3Ja8F5DoX",
    "outputId": "515a14ea-dfc9-4fa9-fa18-e3d391f0effc"
   },
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> Model and Pre-trained weights : </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:17.884610Z",
     "iopub.status.busy": "2025-05-13T02:09:17.884254Z",
     "iopub.status.idle": "2025-05-13T02:09:17.888603Z",
     "shell.execute_reply": "2025-05-13T02:09:17.887922Z",
     "shell.execute_reply.started": "2025-05-13T02:09:17.884578Z"
    },
    "id": "qgWuupVq-G1J"
   },
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:17.889747Z",
     "iopub.status.busy": "2025-05-13T02:09:17.889506Z",
     "iopub.status.idle": "2025-05-13T02:09:17.907674Z",
     "shell.execute_reply": "2025-05-13T02:09:17.907131Z",
     "shell.execute_reply.started": "2025-05-13T02:09:17.889725Z"
    },
    "id": "cxuGG9Ni-GyY"
   },
   "outputs": [],
   "source": [
    "# Note: `userdata.get` is a Colab API. If you're not using Colab, set the env\n",
    "# vars as appropriate or make your credentials available in ~/.kaggle/kaggle.json\n",
    "\n",
    "os.environ[\"...\"]      =    '...'\n",
    "os.environ[\"...\"]      =    '...' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:17.909338Z",
     "iopub.status.busy": "2025-05-13T02:09:17.909116Z",
     "iopub.status.idle": "2025-05-13T02:09:17.923012Z",
     "shell.execute_reply": "2025-05-13T02:09:17.922436Z",
     "shell.execute_reply.started": "2025-05-13T02:09:17.909323Z"
    },
    "id": "Lbpsmqbd-GvR"
   },
   "outputs": [],
   "source": [
    "# The T4 runtime is tight on memory to finetune this model. Preallocate\n",
    "# all memory ahead of time to avoid OOM'ing due to fragmentation.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:18.003401Z",
     "iopub.status.busy": "2025-05-13T02:09:18.002967Z",
     "iopub.status.idle": "2025-05-13T02:09:18.284682Z",
     "shell.execute_reply": "2025-05-13T02:09:18.284086Z",
     "shell.execute_reply.started": "2025-05-13T02:09:18.003385Z"
    },
    "id": "CAaOu2kH-Gsn"
   },
   "outputs": [],
   "source": [
    "# @title Download checkpoint, tokenizer and dataset to local filesystem.\n",
    "#\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:18.285965Z",
     "iopub.status.busy": "2025-05-13T02:09:18.285737Z",
     "iopub.status.idle": "2025-05-13T02:09:18.289738Z",
     "shell.execute_reply": "2025-05-13T02:09:18.288984Z",
     "shell.execute_reply.started": "2025-05-13T02:09:18.285939Z"
    },
    "id": "lwS8F7Y5-Gmy"
   },
   "outputs": [],
   "source": [
    "# Use these for PaliGemma 1:\n",
    "LLM_VARIANT   = \"gemma_2b\"\n",
    "MODEL_PATH    = \"./paligemma-3b-pt-224.f16.npz\"\n",
    "KAGGLE_HANDLE = \"google/paligemma/jax/paligemma-3b-pt-224\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:18.399768Z",
     "iopub.status.busy": "2025-05-13T02:09:18.399322Z",
     "iopub.status.idle": "2025-05-13T02:09:18.699995Z",
     "shell.execute_reply": "2025-05-13T02:09:18.699452Z",
     "shell.execute_reply.started": "2025-05-13T02:09:18.399749Z"
    },
    "id": "MJKsbiCM-GkN",
    "outputId": "32051543-00b3-4f7b-c494-814f29f3396e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the checkpoint from Kaggle, this could take a few minutes....\n",
      "Model path: /kaggle/input/paligemma/jax/paligemma-3b-pt-224/1/./paligemma-3b-pt-224.f16.npz\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(MODEL_PATH):\n",
    "  print(\"Downloading the checkpoint from Kaggle, this could take a few minutes....\")\n",
    "  MODEL_PATH = kagglehub.model_download(KAGGLE_HANDLE, MODEL_PATH)\n",
    "  print(f\"Model path: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:18.701351Z",
     "iopub.status.busy": "2025-05-13T02:09:18.701128Z",
     "iopub.status.idle": "2025-05-13T02:09:18.705736Z",
     "shell.execute_reply": "2025-05-13T02:09:18.704979Z",
     "shell.execute_reply.started": "2025-05-13T02:09:18.701334Z"
    },
    "id": "QFCV-bVi-GhP"
   },
   "outputs": [],
   "source": [
    "TOKENIZER_PATH = \"./paligemma_tokenizer.model\"\n",
    "if not os.path.exists(TOKENIZER_PATH):\n",
    "    print(\"Downloading the model tokenizer...\")\n",
    "    !wget https://storage.googleapis.com/big_vision/paligemma_tokenizer.model -O {TOKENIZER_PATH}\n",
    "    print(f\"Tokenizer path: {TOKENIZER_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skWR8fUu5iU1",
    "outputId": "4338af5f-27a3-4264-8a47-32a48b5db218"
   },
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> Core Library Imports : </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:21.349080Z",
     "iopub.status.busy": "2025-05-13T02:09:21.348832Z",
     "iopub.status.idle": "2025-05-13T02:09:28.888135Z",
     "shell.execute_reply": "2025-05-13T02:09:28.887298Z",
     "shell.execute_reply.started": "2025-05-13T02:09:21.349063Z"
    },
    "id": "zE7BtRvz-Ga3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 02:09:23.697354: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747102163.907660     883 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747102163.967747     883 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import functools\n",
    "import html\n",
    "import io\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import ml_collections\n",
    "\n",
    "import tensorflow as tf\n",
    "import sentencepiece\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from PIL import Image\n",
    "\n",
    "# Import model definition from big_vision\n",
    "from big_vision.models.proj.paligemma import paligemma\n",
    "from big_vision.trainers.proj.paligemma import predict_fns\n",
    "\n",
    "# Import big vision utilities\n",
    "import big_vision.datasets.jsonl\n",
    "import big_vision.utils\n",
    "import big_vision.sharding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:28.889929Z",
     "iopub.status.busy": "2025-05-13T02:09:28.889354Z",
     "iopub.status.idle": "2025-05-13T02:09:30.498898Z",
     "shell.execute_reply": "2025-05-13T02:09:30.498082Z",
     "shell.execute_reply.started": "2025-05-13T02:09:28.889902Z"
    }
   },
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "#                                   Set seeds for reproducibility\n",
    "##################################################################################################################\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "jax_rng_key = jax.random.PRNGKey(SEED)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_2PUPia51SX",
    "outputId": "87163725-49dc-4124-ddd9-dacee11e15ae"
   },
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> Reserve GPU/TPU for JAX </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:30.500628Z",
     "iopub.status.busy": "2025-05-13T02:09:30.499780Z",
     "iopub.status.idle": "2025-05-13T02:09:31.389456Z",
     "shell.execute_reply": "2025-05-13T02:09:31.388644Z",
     "shell.execute_reply.started": "2025-05-13T02:09:30.500599Z"
    },
    "id": "kV8GDGIP51Pn",
    "outputId": "6a2f673e-02bd-41ff-85d4-33bfe400e653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX version:  0.4.33\n",
      "JAX platform: gpu\n",
      "JAX devices:  1\n"
     ]
    }
   ],
   "source": [
    "# Don't let TF use the GPU or TPUs\n",
    "# Disables TensorFlow’s access to GPUs/TPUs so JAX can fully utilize them without resource contention.\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "tf.config.set_visible_devices([], \"TPU\")\n",
    "\n",
    "backend = jax.extend.backend.get_backend() \n",
    "print(f\"JAX version:  {jax.__version__}\")\n",
    "print(f\"JAX platform: {backend.platform}\")\n",
    "print(f\"JAX devices:  {jax.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YQdjtXR5OB9",
    "outputId": "0bd31fa4-f61c-4832-b5d0-5d8b1bede748"
   },
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\">Construct model and load params into RAM </h3>\n",
    "\n",
    " <h5 style=\"color:red;\"> model_config: hyperparameters for both the vision encoder and text decoder.\n",
    "<br>\n",
    "                          Instantiate the combined Vision+LLM model.\n",
    "<br>\n",
    "                          Load pretrained weights into a parameter tree.\n",
    "<br>\n",
    "                          Build a decode function for efficient batched generation.\n",
    "                          </h5>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:31.391044Z",
     "iopub.status.busy": "2025-05-13T02:09:31.390805Z",
     "iopub.status.idle": "2025-05-13T02:09:31.405630Z",
     "shell.execute_reply": "2025-05-13T02:09:31.404901Z",
     "shell.execute_reply.started": "2025-05-13T02:09:31.391026Z"
    }
   },
   "outputs": [],
   "source": [
    "model_config = ml_collections.FrozenConfigDict({\n",
    "    \"llm\": {\"vocab_size\": 257_152, \"variant\": LLM_VARIANT, \"final_logits_softcap\": 0.0},\n",
    "    \"img\": {\"variant\": \"So400m/14\", \"pool_type\": \"none\", \"scan\": True, \"dtype_mm\": \"float16\"}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:31.406757Z",
     "iopub.status.busy": "2025-05-13T02:09:31.406490Z",
     "iopub.status.idle": "2025-05-13T02:09:31.582384Z",
     "shell.execute_reply": "2025-05-13T02:09:31.581650Z",
     "shell.execute_reply.started": "2025-05-13T02:09:31.406733Z"
    },
    "id": "BK3LI-Nh-GUe"
   },
   "outputs": [],
   "source": [
    "model     = paligemma.Model(**model_config)\n",
    "tokenizer = sentencepiece.SentencePieceProcessor(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:09:31.583493Z",
     "iopub.status.busy": "2025-05-13T02:09:31.583215Z",
     "iopub.status.idle": "2025-05-13T02:09:31.595759Z",
     "shell.execute_reply": "2025-05-13T02:09:31.595129Z",
     "shell.execute_reply.started": "2025-05-13T02:09:31.583471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define `decode` function to sample outputs from the model.\n",
    "decode_fn  =   predict_fns.get_all(model)['decode']\n",
    "decode     =   functools.partial(decode_fn, devices=jax.devices(), eos_token=tokenizer.eos_id()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:00.562065Z",
     "iopub.status.busy": "2025-05-13T02:10:00.561515Z",
     "iopub.status.idle": "2025-05-13T02:10:44.420271Z",
     "shell.execute_reply": "2025-05-13T02:10:44.419237Z",
     "shell.execute_reply.started": "2025-05-13T02:10:00.562041Z"
    }
   },
   "outputs": [],
   "source": [
    "PROMPT_LEN  =    10  \n",
    "old_params  =    paligemma.load(None, MODEL_PATH, model_config)\n",
    "\n",
    "soft_prompt =    jax.random.normal(                    \n",
    "                                jax_rng_key,\n",
    "                                (PROMPT_LEN, 2048),   \n",
    "                            ).astype(jnp.float32) \n",
    "\n",
    "# Add it to your param PyTree so it's updated by JAX:\n",
    "params = {\"soft_prompt\": soft_prompt, **old_params} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:46.389126Z",
     "iopub.status.busy": "2025-05-13T02:10:46.388561Z",
     "iopub.status.idle": "2025-05-13T02:10:46.395144Z",
     "shell.execute_reply": "2025-05-13T02:10:46.394278Z",
     "shell.execute_reply.started": "2025-05-13T02:10:46.389098Z"
    }
   },
   "outputs": [],
   "source": [
    "    # Create a pytree mask of the trainable params.\n",
    "    def is_trainable_param(name, param):  # pylint: disable=unused-argument\n",
    "      if name.startswith(\"llm/layers/attn/\"):  return True\n",
    "      if name.startswith(\"soft_prompt\"):       return True  \n",
    "      if name.startswith(\"llm/\"):              return False\n",
    "      if name.startswith(\"img/\"):              return False\n",
    "          \n",
    "      raise ValueError(f\"Unexpected param name {name}\")\n",
    "        \n",
    "    trainable_mask = big_vision.utils.tree_map_with_names(is_trainable_param, params)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> Sharding & Casting Parameters :  </h3>\n",
    "\n",
    "  <h5 style=\"color:red;\">  Sharding: split tensors across devices (if you had >1 GPU).\n",
    "<br>\n",
    "                        maybe_cast_to_f32: keep the frozen weights in fp16 to save memory; cast the few trainable ones to fp32 so their gradients remain stable.\n",
    "<br>\n",
    "                        The loop unpacks the parameter tree, reshares & casts each leaf, and reassembles it.\n",
    "</h5>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:48.991780Z",
     "iopub.status.busy": "2025-05-13T02:10:48.991434Z",
     "iopub.status.idle": "2025-05-13T02:10:48.996204Z",
     "shell.execute_reply": "2025-05-13T02:10:48.995395Z",
     "shell.execute_reply.started": "2025-05-13T02:10:48.991754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Yes: Some donated buffers are not usable.\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", message=\"Some donated buffers were not usable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:49.168990Z",
     "iopub.status.busy": "2025-05-13T02:10:49.168755Z",
     "iopub.status.idle": "2025-05-13T02:10:49.173703Z",
     "shell.execute_reply": "2025-05-13T02:10:49.172870Z",
     "shell.execute_reply.started": "2025-05-13T02:10:49.168969Z"
    },
    "id": "68c533b0-e398-4508-bba6-c8271e76a9f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, donate_argnums=(0,), static_argnums=(1,))\n",
    "def maybe_cast_to_f32(params, trainable):\n",
    "  # Cast others to float16, since some GPUs don't support bf16.\n",
    "  return jax.tree.map(lambda p, m: p.astype(jnp.float32)\n",
    "                      if m else p.astype(jnp.float16),\n",
    "                      params, trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T21:05:03.618581Z",
     "iopub.status.busy": "2025-05-01T21:05:03.618308Z",
     "iopub.status.idle": "2025-05-01T21:05:03.623664Z",
     "shell.execute_reply": "2025-05-01T21:05:03.623032Z",
     "shell.execute_reply.started": "2025-05-01T21:05:03.61856Z"
    },
    "id": "WH_1HRpMqhuW",
    "outputId": "a6037f1d-e8cf-436c-d18a-47404ff945eb"
   },
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> Define preprocess functions to create inputs to the model :  </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:51.077916Z",
     "iopub.status.busy": "2025-05-13T02:10:51.077599Z",
     "iopub.status.idle": "2025-05-13T02:10:51.088927Z",
     "shell.execute_reply": "2025-05-13T02:10:51.088029Z",
     "shell.execute_reply.started": "2025-05-13T02:10:51.077891Z"
    },
    "id": "0zrFyYeVEAHD"
   },
   "outputs": [],
   "source": [
    "# @title Define preprocess functions to create inputs to the model.\n",
    "\n",
    "def preprocess_image(image, size=224):\n",
    "  # Model has been trained to handle images of different aspects ratios\n",
    "  # resized to 224x224 in the range [-1, 1]. Bilinear and antialias resize\n",
    "  # options are helpful to improve quality in some tasks.\n",
    "  image = np.asarray(image)\n",
    "  if image.ndim == 2:  # Convert image without last channel into greyscale.\n",
    "    image = np.stack((image,)*3, axis=-1)\n",
    "  image = image[..., :3]  # Remove alpha layer.\n",
    "  assert image.shape[-1] == 3\n",
    "\n",
    "  image = tf.constant(image)\n",
    "  image = tf.image.resize(image, (size, size), method='bilinear', antialias=True)\n",
    "  return image.numpy() / 127.5 - 1.0  # [0, 255]->[-1,1]\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------# \n",
    "#----------------------------------------------------------------------------------------------#\n",
    "def preprocess_tokens(suffix: str | None, seqlen: int = None,  PROMPT_LEN : int = None): \n",
    "    \"\"\"\n",
    "    Tokenize only the suffix (caption) and build masks,\n",
    "    leaving room for PROMPT_LEN soft‐prompt embeddings.\n",
    "\n",
    "    Returns:\n",
    "      tokens      : np.int32 array of length seqlen (or PROMPT_LEN if no suffix)\n",
    "      mask_ar     : np.int32 array, 0=full attention (for prefix), 1=causal (for suffix)\n",
    "      mask_loss   : np.int32 array, 0=no loss on prefix, 1=loss on suffix\n",
    "      mask_input  : np.int32 array, 1=real token, 0=padding\n",
    "    \"\"\"\n",
    "    # 1) Tokenize suffix if given\n",
    "    if suffix is not None:\n",
    "        # separator token\n",
    "        sep_ids = tokenizer.encode(\"\\n\", add_bos=False, add_eos=False)\n",
    "        suf_ids = tokenizer.encode(suffix, add_bos=False, add_eos=True)\n",
    "        \n",
    "        tokens_suf    = sep_ids + suf_ids\n",
    "        mask_ar_suf   = [1] * len(tokens_suf)\n",
    "        mask_loss_suf = [1] * len(tokens_suf)\n",
    "    else:\n",
    "        tokens_suf    = []\n",
    "        mask_ar_suf   = []\n",
    "        mask_loss_suf = []\n",
    "\n",
    "    # 2) Build the combined sequence\n",
    "    #    Prefix (soft prompts) occupy positions [0..PROMPT_LEN-1], so we\n",
    "    #    start our discrete IDs at index PROMPT_LEN.\n",
    "    tokens     = [0] * PROMPT_LEN  + tokens_suf\n",
    "    mask_ar    = [0] * PROMPT_LEN  + mask_ar_suf\n",
    "    mask_loss  = [0] * PROMPT_LEN  + mask_loss_suf\n",
    "    mask_input = [0] * PROMPT_LEN  + [1] * len(tokens_suf)\n",
    "\n",
    "    # 3) Pad/truncate to seqlen if requested\n",
    "    if seqlen is not None:\n",
    "        length = len(tokens)\n",
    "        if length < seqlen:\n",
    "            pad_len = seqlen - length\n",
    "            tokens     += [0] * pad_len\n",
    "            mask_ar    += [0] * pad_len\n",
    "            mask_loss  += [0] * pad_len\n",
    "            mask_input += [0] * pad_len\n",
    "        else:\n",
    "            tokens     = tokens[:seqlen]\n",
    "            mask_ar    = mask_ar[:seqlen]\n",
    "            mask_loss  = mask_loss[:seqlen]\n",
    "            mask_input = mask_input[:seqlen]\n",
    "\n",
    "    # 4) Return as arrays\n",
    "    return (\n",
    "        np.array(tokens,     dtype=np.int32),\n",
    "        np.array(mask_ar,    dtype=np.int32),\n",
    "        np.array(mask_loss,  dtype=np.int32),\n",
    "        np.array(mask_input, dtype=np.int32),\n",
    "    )\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "def postprocess_tokens(tokens):\n",
    "  tokens = tokens.tolist()  # np.array to list[int]\n",
    "  try:  # Remove tokens at and after EOS if any.\n",
    "    eos_pos = tokens.index(tokenizer.eos_id())\n",
    "    tokens = tokens[:eos_pos]\n",
    "  except ValueError:\n",
    "    pass\n",
    "  return tokenizer.decode(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SoyORZgquEe",
    "outputId": "7f3a2fa9-144c-4deb-e7b0-9466ffe8d1bf"
   },
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> Import Data  :  </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:53.763811Z",
     "iopub.status.busy": "2025-05-13T02:10:53.763220Z",
     "iopub.status.idle": "2025-05-13T02:10:53.767610Z",
     "shell.execute_reply": "2025-05-13T02:10:53.766624Z",
     "shell.execute_reply.started": "2025-05-13T02:10:53.763781Z"
    },
    "id": "_HgszSHUGy0A"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:53.998988Z",
     "iopub.status.busy": "2025-05-13T02:10:53.998744Z",
     "iopub.status.idle": "2025-05-13T02:10:54.387045Z",
     "shell.execute_reply": "2025-05-13T02:10:54.386376Z",
     "shell.execute_reply.started": "2025-05-13T02:10:53.998968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  source split           image  \\\n",
      "0   NWPU  test  NWPU_31430.jpg   \n",
      "1   NWPU  test  NWPU_31431.jpg   \n",
      "2   NWPU  test  NWPU_31432.jpg   \n",
      "3   NWPU  test  NWPU_31433.jpg   \n",
      "4   NWPU  test  NWPU_31434.jpg   \n",
      "\n",
      "                                           caption_1  \\\n",
      "0   A gray plane on the runway and the lawn beside .   \n",
      "1  Three small planes parked in a line on the air...   \n",
      "2  A plane parked in a line on the airport with s...   \n",
      "3  A small plane and a big plane parked next to b...   \n",
      "4       Two planes parked next to boarding bridges .   \n",
      "\n",
      "                                           caption_2  \\\n",
      "0        A grey plane is on the runway by the lawn .   \n",
      "1  There are four aircraft on the open ground, Th...   \n",
      "2  A white plane was parked on the instruction li...   \n",
      "3  A white plane and a gray plane parked at the b...   \n",
      "4  Two aircraft were parked at the departure gates .   \n",
      "\n",
      "                                           caption_3  \\\n",
      "0  There is an airplane on the runway with a larg...   \n",
      "1  There are many planes of different sizes in a ...   \n",
      "2  An airplane parked in an open area with many c...   \n",
      "3  Two planes of different sizes are neatly parke...   \n",
      "4  Two planes of different sizes are neatly parke...   \n",
      "\n",
      "                                           caption_4  \\\n",
      "0  A plane is parked on the runway next to the gr...   \n",
      "1             Four planes are parked on the runway .   \n",
      "2              A plane is parked on the open space .   \n",
      "3  A large plane and a small plane are parked nea...   \n",
      "4       Two planes are parked next to the terminal .   \n",
      "\n",
      "                                           caption_5  \n",
      "0  There is a plane on the runway beside the grass .  \n",
      "1  Four planes of different sizes were on the mar...  \n",
      "2            There is 1 plane on the ground marked .  \n",
      "3              Two planes are on the marked ground .  \n",
      "4              Two planes are on the marked ground .  \n"
     ]
    }
   ],
   "source": [
    "captions_df = pd.read_csv('/kaggle/input/rsics-dataset/captions.csv') \n",
    "print(captions_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:54.388627Z",
     "iopub.status.busy": "2025-05-13T02:10:54.388323Z",
     "iopub.status.idle": "2025-05-13T02:10:54.392536Z",
     "shell.execute_reply": "2025-05-13T02:10:54.391827Z",
     "shell.execute_reply.started": "2025-05-13T02:10:54.388608Z"
    },
    "id": "1s_HUEaOGvCn"
   },
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_ROOT = \"/kaggle/input/rsics-dataset/resized\" \n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE   = (224, 224) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:54.393389Z",
     "iopub.status.busy": "2025-05-13T02:10:54.393149Z",
     "iopub.status.idle": "2025-05-13T02:10:54.418368Z",
     "shell.execute_reply": "2025-05-13T02:10:54.417524Z",
     "shell.execute_reply.started": "2025-05-13T02:10:54.393372Z"
    },
    "id": "-F5zSNzPKHOu",
    "outputId": "43cfff8b-ca10-4bdb-e768-a8f374611bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All split labels: ['test' 'val' 'train']\n",
      "Counts:\n",
      " split\n",
      "train    35614\n",
      "test      4454\n",
      "val       4453\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"All split labels:\", captions_df['split'].unique())\n",
    "print(\"Counts:\\n\", captions_df['split'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:54.596333Z",
     "iopub.status.busy": "2025-05-13T02:10:54.596127Z",
     "iopub.status.idle": "2025-05-13T02:10:54.617816Z",
     "shell.execute_reply": "2025-05-13T02:10:54.617091Z",
     "shell.execute_reply.started": "2025-05-13T02:10:54.596316Z"
    },
    "id": "bYrO8v1UKHL4"
   },
   "outputs": [],
   "source": [
    "# 4. Filter into splits\n",
    "splits = {}\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    splits[split_name] = captions_df[captions_df['split'] == split_name] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:54.760108Z",
     "iopub.status.busy": "2025-05-13T02:10:54.759724Z",
     "iopub.status.idle": "2025-05-13T02:10:54.764281Z",
     "shell.execute_reply": "2025-05-13T02:10:54.763627Z",
     "shell.execute_reply.started": "2025-05-13T02:10:54.760089Z"
    },
    "id": "9boO9ocTKGiO"
   },
   "outputs": [],
   "source": [
    "# 5. Convert each split-DataFrame into (paths, captions)\n",
    "def df_to_paths_and_captions(split_df):\n",
    "    # Full paths\n",
    "    paths = split_df['image'].apply(lambda fn: os.path.join(IMAGE_ROOT, fn)).tolist()\n",
    "    # List-of-captions per example\n",
    "    captions_cols = [f'caption_{i}' for i in range(1,6)]\n",
    "    captions = split_df[captions_cols].values.tolist()\n",
    "    return paths, captions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:57.623950Z",
     "iopub.status.busy": "2025-05-13T02:10:57.623582Z",
     "iopub.status.idle": "2025-05-13T02:10:57.630538Z",
     "shell.execute_reply": "2025-05-13T02:10:57.629702Z",
     "shell.execute_reply.started": "2025-05-13T02:10:57.623926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4453"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:57.830925Z",
     "iopub.status.busy": "2025-05-13T02:10:57.830301Z",
     "iopub.status.idle": "2025-05-13T02:10:57.897220Z",
     "shell.execute_reply": "2025-05-13T02:10:57.896676Z",
     "shell.execute_reply.started": "2025-05-13T02:10:57.830905Z"
    },
    "id": "UTtccQ1oIP7S"
   },
   "outputs": [],
   "source": [
    "train_paths, train_caps = df_to_paths_and_captions(splits['train']) \n",
    "val_paths,   val_caps   = df_to_paths_and_captions(splits['val']) \n",
    "test_paths,  test_caps  = df_to_paths_and_captions(splits['test']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:58.006148Z",
     "iopub.status.busy": "2025-05-13T02:10:58.005942Z",
     "iopub.status.idle": "2025-05-13T02:10:58.010935Z",
     "shell.execute_reply": "2025-05-13T02:10:58.010320Z",
     "shell.execute_reply.started": "2025-05-13T02:10:58.006132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4453"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:58.196064Z",
     "iopub.status.busy": "2025-05-13T02:10:58.195837Z",
     "iopub.status.idle": "2025-05-13T02:10:58.202061Z",
     "shell.execute_reply": "2025-05-13T02:10:58.201466Z",
     "shell.execute_reply.started": "2025-05-13T02:10:58.196046Z"
    },
    "id": "Wgpm8HTEISvx"
   },
   "outputs": [],
   "source": [
    "# 6. Preprocessing fn: load image + return captions list\n",
    "def _load_and_preprocess(path, captions):\n",
    "    # Read & decode\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    # Resize & normalize\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img, captions\n",
    "\n",
    "# 7. Build the tf.data pipeline\n",
    "def make_dataset(paths, captions, shuffle=False):\n",
    "    # turn your Python list-of-strings into a tf.string tensor\n",
    "    paths_ds = tf.data.Dataset.from_tensor_slices(tf.constant(paths, dtype=tf.string))\n",
    "    # turn your list-of-lists-of-strings into a [5] tf.string tensor\n",
    "    caps_ds  = tf.data.Dataset.from_tensor_slices(tf.constant(captions, dtype=tf.string))\n",
    "\n",
    "    ds = tf.data.Dataset.zip((paths_ds, caps_ds))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(paths))\n",
    "    ds = ( ds\n",
    "           .map(_load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "           .batch(BATCH_SIZE)\n",
    "           .prefetch(tf.data.AUTOTUNE) \n",
    "         )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:10:58.437730Z",
     "iopub.status.busy": "2025-05-13T02:10:58.437505Z",
     "iopub.status.idle": "2025-05-13T02:10:58.598547Z",
     "shell.execute_reply": "2025-05-13T02:10:58.597690Z",
     "shell.execute_reply.started": "2025-05-13T02:10:58.437712Z"
    },
    "id": "oWuvduvbIE-H"
   },
   "outputs": [],
   "source": [
    "train_ds = make_dataset(train_paths, train_caps, shuffle=True)\n",
    "val_ds   = make_dataset(val_paths,   val_caps,   shuffle=True) \n",
    "test_ds  = make_dataset(test_paths,  test_caps,  shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:11:00.561847Z",
     "iopub.status.busy": "2025-05-13T02:11:00.561012Z",
     "iopub.status.idle": "2025-05-13T02:11:00.569666Z",
     "shell.execute_reply": "2025-05-13T02:11:00.568712Z",
     "shell.execute_reply.started": "2025-05-13T02:11:00.561817Z"
    },
    "id": "emSWd_NsEAEA"
   },
   "outputs": [],
   "source": [
    "def train_data_iterator(PROMPT_LEN, SEQLEN):\n",
    "    \"\"\"Never-ending iterator over training examples from train_ds.\"\"\"\n",
    "    while True:\n",
    "        for image_batch, caps_batch in train_ds:\n",
    "            images_np = image_batch.numpy()      # [B,H,W,3]\n",
    "            caps_np   = caps_batch.numpy()       # [B,5] bytes\n",
    "\n",
    "            for img, caps in zip(images_np, caps_np):\n",
    "                decoded_caps = [c.decode('utf-8') for c in caps]             #  All Captions\n",
    "                \n",
    "                rng    = np.random.default_rng(SEED)                         # We can not randomly choose anymore ! \n",
    "                suffix = decoded_caps[rng.integers(5)].lower()\n",
    "\n",
    "\n",
    "                # Prepare tokens and masks\n",
    "                tokens, mask_ar, mask_loss, mask_in   =  preprocess_tokens( suffix,  SEQLEN,   PROMPT_LEN ) \n",
    "                \n",
    "                img_proc = img * 2.0 - 1.0\n",
    "                yield [{\n",
    "                    \"image\": img_proc,\n",
    "                    \"text\": np.asarray(tokens, dtype=np.int32),\n",
    "                    \"mask_ar\": np.asarray(mask_ar, dtype=np.int32),\n",
    "                    \"mask_loss\": np.asarray(mask_loss, dtype=np.int32),\n",
    "                    \"mask_input\": np.asarray(mask_in,  dtype=np.int32),  # ← Add this\n",
    "                }, decoded_caps] \n",
    "\n",
    "def validation_data_iterator(PROMPT_LEN, SEQLEN): \n",
    "    \"\"\"Single-pass iterator over validation examples from val_ds.\"\"\"\n",
    "    \n",
    "    for image_batch, caps_batch in val_ds:\n",
    "        \n",
    "        images_np = image_batch.numpy()\n",
    "        caps_np   = caps_batch.numpy()\n",
    "\n",
    "        for img, caps in zip(images_np, caps_np):\n",
    "            decoded_caps = [c.decode('utf-8') for c in caps]       #  All Captions \n",
    "\n",
    "            # Prepare tokens and masks\n",
    "            tokens, mask_ar, mask_loss, mask_in   =  preprocess_tokens( None,  SEQLEN,  PROMPT_LEN)    # suffix = None \n",
    "            \n",
    "            img_proc = img * 2. - 1.\n",
    "            yield [{\n",
    "                \"image\": img_proc,\n",
    "                \"text\": np.asarray(tokens, dtype=np.int32),\n",
    "                \"mask_input\": np.asarray(mask_in, dtype=np.int32),\n",
    "                \"mask_ar\": np.asarray(mask_ar, dtype=np.int32), \n",
    "            }, decoded_caps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHiB8o5aIE7W",
    "outputId": "46e0af8e-5669-4b41-f51b-d15f607cb4dc"
   },
   "outputs": [],
   "source": [
    "# 8. Quick sanity check\n",
    "for imgs, caps in test_ds.take(1):\n",
    "    print(\"Images batch shape:\", imgs.shape)            # (BATCH_SIZE, H, W, 3)\n",
    "    print(\"Captions batch shape:\", len(caps), \"examples\")\n",
    "    print(\"First example captions:\", caps[0])            # a list of 5 strings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> Evaluation / Inference Loop :  </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:11:05.029232Z",
     "iopub.status.busy": "2025-05-13T02:11:05.028681Z",
     "iopub.status.idle": "2025-05-13T02:11:05.033149Z",
     "shell.execute_reply": "2025-05-13T02:11:05.032289Z",
     "shell.execute_reply.started": "2025-05-13T02:11:05.029204Z"
    }
   },
   "outputs": [],
   "source": [
    "SEQLEN  =  128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:11:05.250983Z",
     "iopub.status.busy": "2025-05-13T02:11:05.250260Z",
     "iopub.status.idle": "2025-05-13T02:11:05.257941Z",
     "shell.execute_reply": "2025-05-13T02:11:05.257288Z",
     "shell.execute_reply.started": "2025-05-13T02:11:05.250957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation/inference loop.\n",
    "def make_predictions(data_iterator, *, num_examples=None,\n",
    "                     batch_size=4, seqlen=SEQLEN, sampler=\"greedy\"):\n",
    "  outputs = []\n",
    "  while True:\n",
    "    # Construct a list of examples in the batch.\n",
    "    examples = []\n",
    "    captions = [] \n",
    "    try:\n",
    "      for _ in range(batch_size):\n",
    "\n",
    "        example, caps = next(data_iterator) \n",
    "        example[\"_mask\"]   = np.array(True)\n",
    "        example[\"caption\"] = caps\n",
    "        \n",
    "        # Keep the caption aside\n",
    "        caption = example.pop(\"caption\") \n",
    "        captions.append(caption)\n",
    "        \n",
    "        examples.append(example)\n",
    "\n",
    "\n",
    "    except StopIteration:\n",
    "      if len(examples) == 0:\n",
    "        return outputs\n",
    "\n",
    "    # Not enough examples to complete a batch. Pad by repeating last example.\n",
    "    while len(examples) % batch_size:\n",
    "      examples.append(dict(examples[-1]))\n",
    "      examples[-1][\"_mask\"] = np.array(False)  # Indicates padding example.\n",
    "\n",
    "    # Convert list of examples into a dict of np.arrays and load onto devices.\n",
    "    batch = jax.tree.map(lambda *x: np.stack(x), *examples)\n",
    "    #batch = big_vision.utils.reshard(batch, data_sharding)\n",
    "\n",
    "    # Make model predictions\n",
    "    tokens = decode({\"params\": params}, batch=batch,\n",
    "                    max_decode_len=seqlen, sampler=sampler)\n",
    "\n",
    "    # Fetch model predictions to device and detokenize.\n",
    "    tokens, mask = jax.device_get((tokens, batch[\"_mask\"]))\n",
    "    tokens = tokens[mask]  # remove padding examples.\n",
    "    responses = [postprocess_tokens(t) for t in tokens]\n",
    "\n",
    "    # Append to html output.\n",
    "    for example, response, caption in zip(examples, responses, captions):\n",
    "        outputs.append((example[\"image\"], response, caption))\n",
    "   \n",
    "        if num_examples and len(outputs) >= num_examples:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it   =   validation_data_iterator(10, 32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out  =  make_predictions(it, num_examples=8,\n",
    "                                 batch_size=8, seqlen=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[num][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T07:37:59.333628Z",
     "iopub.status.busy": "2025-05-02T07:37:59.333126Z",
     "iopub.status.idle": "2025-05-02T07:37:59.339059Z",
     "shell.execute_reply": "2025-05-02T07:37:59.337947Z",
     "shell.execute_reply.started": "2025-05-02T07:37:59.333604Z"
    },
    "id": "PuqC8L--tMhq",
    "outputId": "bcb50f18-7b1b-4b57-fd84-2b3156af0f0f"
   },
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> WANDB :  </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:11:09.681786Z",
     "iopub.status.busy": "2025-05-13T02:11:09.681470Z",
     "iopub.status.idle": "2025-05-13T02:11:11.070910Z",
     "shell.execute_reply": "2025-05-13T02:11:11.070318Z",
     "shell.execute_reply.started": "2025-05-13T02:11:09.681763Z"
    },
    "id": "5aDEF3c_VE0U"
   },
   "outputs": [],
   "source": [
    "import wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:11:11.072838Z",
     "iopub.status.busy": "2025-05-13T02:11:11.072457Z",
     "iopub.status.idle": "2025-05-13T02:11:11.076762Z",
     "shell.execute_reply": "2025-05-13T02:11:11.076167Z",
     "shell.execute_reply.started": "2025-05-13T02:11:11.072813Z"
    },
    "id": "pJd2cBlEVBuQ",
    "outputId": "d56a4eaf-a729-4928-851e-1973ffbfdd97"
   },
   "outputs": [],
   "source": [
    "os.environ[\"...\"]       = \"...\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:11:11.077822Z",
     "iopub.status.busy": "2025-05-13T02:11:11.077575Z",
     "iopub.status.idle": "2025-05-13T02:11:17.270807Z",
     "shell.execute_reply": "2025-05-13T02:11:17.270031Z",
     "shell.execute_reply.started": "2025-05-13T02:11:11.077805Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mturgay-yildiz-phi-e-pi\u001b[0m (\u001b[33mDI_725___Final_Project\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> Hyper-Parameter Tuning & Ablation Study :  </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:11:30.641907Z",
     "iopub.status.busy": "2025-05-13T02:11:30.640780Z",
     "iopub.status.idle": "2025-05-13T02:11:38.357388Z",
     "shell.execute_reply": "2025-05-13T02:11:38.356810Z",
     "shell.execute_reply.started": "2025-05-13T02:11:30.641864Z"
    }
   },
   "outputs": [],
   "source": [
    "import io, base64\n",
    "from PIL import Image \n",
    "\n",
    "import pickle\n",
    "import evaluate\n",
    "import tqdm\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:11:38.359251Z",
     "iopub.status.busy": "2025-05-13T02:11:38.358688Z",
     "iopub.status.idle": "2025-05-13T02:11:50.308009Z",
     "shell.execute_reply": "2025-05-13T02:11:50.307248Z",
     "shell.execute_reply.started": "2025-05-13T02:11:38.359231Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################################\n",
    "#                                         Install & load metrics                                                 #                       \n",
    "##################################################################################################################\n",
    "from evaluate import load as load_metric\n",
    "bleu_metric   = evaluate.load(\"bleu\")\n",
    "rouge_metric  = evaluate.load(\"rouge\")\n",
    "meteor_metric = evaluate.load(\"meteor\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:11:50.309067Z",
     "iopub.status.busy": "2025-05-13T02:11:50.308822Z",
     "iopub.status.idle": "2025-05-13T02:11:50.315997Z",
     "shell.execute_reply": "2025-05-13T02:11:50.315328Z",
     "shell.execute_reply.started": "2025-05-13T02:11:50.309049Z"
    }
   },
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, donate_argnums=(0,))\n",
    "def update_fn(params, batch, learning_rate):\n",
    "  imgs, txts, mask_ar = batch[\"image\"], batch[\"text\"], batch[\"mask_ar\"]\n",
    "\n",
    "  def loss_fn(params):\n",
    "    text_logits, _ = model.apply({\"params\": params}, imgs, txts[:, :-1], mask_ar[:, :-1], train=True)\n",
    "    logp = jax.nn.log_softmax(text_logits, axis=-1)\n",
    "\n",
    "    # The model takes as input txts[:, :-1] but the loss is defined as predicting\n",
    "    # next tokens txts[:, 1:]. Additionally, mask_loss[:, 1:] indicates which tokens\n",
    "    # are part of the loss (e.g. prefix and padded tokens are not included).\n",
    "    mask_loss = batch[\"mask_loss\"][:, 1:]\n",
    "    targets = jax.nn.one_hot(txts[:, 1:], text_logits.shape[-1])\n",
    "\n",
    "    # Compute the loss per example. i.e. the mean of per token pplx.\n",
    "    # Since each example has a different number of tokens we normalize it.\n",
    "    token_pplx = jnp.sum(logp * targets, axis=-1)  # sum across vocab_size.\n",
    "    example_loss = -jnp.sum(token_pplx * mask_loss, axis=-1)  # sum across seq_len.\n",
    "    example_loss /= jnp.clip(jnp.sum(mask_loss, -1), 1)  # weight by num of tokens.\n",
    "\n",
    "    # batch_loss: mean of per example loss.\n",
    "    return jnp.mean(example_loss)\n",
    "\n",
    "  loss, grads = jax.value_and_grad(loss_fn)(params)\n",
    "\n",
    "  # Apply gradients to trainable params using SGD.\n",
    "  def apply_grad(param, gradient, trainable):\n",
    "    if not trainable: return param\n",
    "    return param - learning_rate * gradient\n",
    "\n",
    "  params = jax.tree_util.tree_map(apply_grad, params, grads, trainable_mask)\n",
    "\n",
    "  return params, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:11:57.112791Z",
     "iopub.status.busy": "2025-05-13T02:11:57.112146Z",
     "iopub.status.idle": "2025-05-13T02:11:57.128132Z",
     "shell.execute_reply": "2025-05-13T02:11:57.127346Z",
     "shell.execute_reply.started": "2025-05-13T02:11:57.112765Z"
    },
    "id": "l0_hf0XgD_yE"
   },
   "outputs": [],
   "source": [
    "def train(config=None):  \n",
    "\n",
    "##################################################################################################################\n",
    "#                                   Initialize params\n",
    "##################################################################################################################\n",
    "    PROMPT_LEN  =    10  \n",
    "    old_params  =    paligemma.load(None, MODEL_PATH, model_config)\n",
    "\n",
    "    soft_prompt =    jax.random.normal(                    # since this is deleted after training, we need to define it each time (sweep). \n",
    "                                    jax_rng_key,\n",
    "                                    (PROMPT_LEN, 2048),   \n",
    "                                ).astype(jnp.float32) \n",
    "    \n",
    "    # Add it to your param PyTree so it's updated by JAX:\n",
    "    params = {\"soft_prompt\": soft_prompt, **old_params} \n",
    "\n",
    "##################################################################################################################\n",
    "#                                   Initialize a new wandb run\n",
    "##################################################################################################################\n",
    "    \n",
    "    with wandb.init(config=config): \n",
    "    \n",
    "##################################################################################################################\n",
    "#                                                  read config                                                   #\n",
    "##################################################################################################################        \n",
    "        cfg   =    wandb.config \n",
    "    \n",
    "##################################################################################################################    \n",
    "#                                        Unpack hyper-parameters & flags                                         #                     \n",
    "##################################################################################################################\n",
    "        BATCH_SIZE     =   cfg.batch_size\n",
    "        LEARNING_RATE  =   cfg.learning_rate\n",
    "        SEQLEN         =   cfg.seqlen \n",
    "        \n",
    "        TRAIN_STEPS    = 201  \n",
    "        TRAIN_EXAMPLES = TRAIN_STEPS * BATCH_SIZE \n",
    "        eval_steps     = 100  \n",
    "##################################################################################################################   \n",
    "#                                              Training loop                                                     # \n",
    "##################################################################################################################\n",
    "\n",
    "        train_it     = train_data_iterator(PROMPT_LEN, SEQLEN)    \n",
    "    \n",
    "        sched_fn = big_vision.utils.create_learning_rate_schedule( \n",
    "            total_steps=TRAIN_STEPS+1,\n",
    "            base=LEARNING_RATE,\n",
    "            decay_type=cfg.lr_decay,\n",
    "            warmup_percent=cfg.warmup_percent,\n",
    "        )\n",
    "        \n",
    "        for step in range(1, TRAIN_STEPS + 1): \n",
    "    \n",
    "            examples = [next(train_it)[0] for _ in range(BATCH_SIZE)] \n",
    "        \n",
    "            batch    = jax.tree.map(lambda *x: np.stack(x), *examples) \n",
    "            #batch    = big_vision.utils.reshard(batch, data_sharding)\n",
    "        \n",
    "            lr           = sched_fn(step)\n",
    "            params, loss = update_fn(params,  batch, lr)   \n",
    "            loss_val     = float(jax.device_get(loss))\n",
    "        \n",
    "            print(f\"step: {step}/{TRAIN_STEPS}   lr: {lr:.8f}   loss: {loss_val:.4f}\")\n",
    "            wandb.log({\"train/loss\": loss_val, \"train/lr\": lr}, step=step)\n",
    "            \n",
    "##################################################################################################################\n",
    "#                                           Evaluation :                                                         #\n",
    "##################################################################################################################\n",
    "            if step % eval_steps == 0: \n",
    "                print(f\"→ Evaluation at step {step}\")\n",
    "    \n",
    "                # A) Batch‐collect all validation examples once\n",
    "                all_examples = []\n",
    "                all_captions = []\n",
    "        \n",
    "                \n",
    "                # one call, batch_size=TOTAL to run one forward of 8\n",
    "                demo_outputs = make_predictions(\n",
    "                                                validation_data_iterator(PROMPT_LEN, SEQLEN),\n",
    "                                                num_examples=8,\n",
    "                                                batch_size=8,\n",
    "                                            )\n",
    "                \n",
    "                \n",
    "                # demo_outputs is a list of (img, pred, ref) of length num_to_eval\n",
    "                all_hyps = [pred for (_, pred, _) in demo_outputs]\n",
    "                all_refs = [[ref] for (_, _, ref) in demo_outputs] \n",
    "    \n",
    "##################################################################################################################\n",
    "#                                          compute & log BLEU/ROUGE/METEOR                                       # \n",
    "##################################################################################################################\n",
    "                # 1) Filter out any fully empty predictions\n",
    "                # Filter out any empty predictions, just in case\n",
    "                filtered = [(h, refs) for h, refs in zip(all_hyps, all_refs) if h.strip()]\n",
    "                if filtered:\n",
    "                    all_hyps, all_refs = zip(*filtered)\n",
    "                    all_hyps, all_refs = list(all_hyps), list(all_refs)\n",
    "                else:\n",
    "                    all_hyps, all_refs = [], []\n",
    "        \n",
    "                # Only call metrics if we have at least one example\n",
    "                if all_hyps:\n",
    "                    bleu_res = bleu_metric.compute(\n",
    "                        predictions=all_hyps,\n",
    "                        references=all_refs,\n",
    "                        smooth=True   # avoid zero‐div errors\n",
    "                    )\n",
    "                    rouge_res = rouge_metric.compute(\n",
    "                        predictions=all_hyps,\n",
    "                        references=all_refs\n",
    "                    )\n",
    "                    meteor_res = meteor_metric.compute(\n",
    "                        predictions=all_hyps,\n",
    "                        references=all_refs\n",
    "                    )\n",
    "                else:\n",
    "                    # no valid hyps → set everything to zero\n",
    "                    bleu_res   = {\"bleu\": 0.0}\n",
    "                    rouge_res  = {\"rouge1\": 0.0, \"rouge2\": 0.0, \"rougeL\": 0.0}\n",
    "                    meteor_res = {\"meteor\": 0.0}\n",
    "        \n",
    "                print(f\"   BLEU:   {bleu_res['bleu']:.3f}\")\n",
    "                print(f\"   ROUGE1: {rouge_res['rouge1']:.3f}, ROUGE2: {rouge_res['rouge2']:.3f}, ROUGEL: {rouge_res['rougeL']:.3f}\")\n",
    "                print(f\"   METEOR: {meteor_res['meteor']:.3f}\")\n",
    "        \n",
    "                wandb.log({\n",
    "                    \"eval/bleu\":    bleu_res[\"bleu\"],\n",
    "                    \"eval/rouge1\":  rouge_res[\"rouge1\"],\n",
    "                    \"eval/rouge2\":  rouge_res[\"rouge2\"],\n",
    "                    \"eval/rougeL\":  rouge_res[\"rougeL\"],\n",
    "                    \"eval/meteor\":  meteor_res[\"meteor\"],\n",
    "                }, step=step)\n",
    "        \n",
    "##################################################################################################################\n",
    "#                                           Display side‐by‐side \n",
    "##################################################################################################################\n",
    "\n",
    "                sample_outputs = demo_outputs[:4] \n",
    "                \n",
    "                html = \"<div style='display:flex; gap:16px;'>\"\n",
    "                for img, pred, ref in sample_outputs:\n",
    "                    img_u8 = ((img + 1) * 127.5).astype(\"uint8\")\n",
    "                    buf    = io.BytesIO()\n",
    "                    Image.fromarray(img_u8).save(buf, format=\"PNG\")\n",
    "                    b64    = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "                    html += f\"\"\"\n",
    "                      <div style='text-align:center;'>\n",
    "                        <img src=\"data:image/png;base64,{b64}\" width=\"200\"/><br/>\n",
    "                        <strong>Pred:</strong> {pred}<br/>\n",
    "                        <strong>Ref:</strong> {ref}\n",
    "                      </div>\n",
    "                    \"\"\"\n",
    "                html += \"</div>\"\n",
    "                display(HTML(html))\n",
    "##################################################################################################################\n",
    "#                                               W&B table \n",
    "##################################################################################################################\n",
    "                table = wandb.Table(columns=[\"image\",\"predicted\",\"reference\"])\n",
    "                for img, pred, ref in sample_outputs:\n",
    "                    wb_img = wandb.Image(((img + 1) * 127.5).astype(\"uint8\"))\n",
    "                    table.add_data(wb_img, pred, ref)\n",
    "                wandb.log({\"eval/samples_table\": table}, step=step)\n",
    "##################################################################################################################  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YamfwMqsD_hM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> W&B Sweep Configuration :  </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:12:00.317885Z",
     "iopub.status.busy": "2025-05-13T02:12:00.317114Z",
     "iopub.status.idle": "2025-05-13T02:12:00.322816Z",
     "shell.execute_reply": "2025-05-13T02:12:00.321934Z",
     "shell.execute_reply.started": "2025-05-13T02:12:00.317854Z"
    }
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "\n",
    "#########################################################################################################################\n",
    "#                                                Metric\n",
    "#########################################################################################################################  \n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"eval/meteor\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "#########################################################################################################################\n",
    "#                                                Hyper-Parameters \n",
    "#########################################################################################################################\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\n",
    "            \"values\" : [0.001, 0.0001, 0.00001]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [2, 4, 6] \n",
    "        },\n",
    "        \"warmup_percent\": {\n",
    "            \"values\": [0.01, 0.05]\n",
    "        },\n",
    "        \"seqlen\": {\n",
    "            \"values\": [16, 32, 64] \n",
    "        },\n",
    "        \"lr_decay\": {\n",
    "            \"values\": [\"cosine\", \"linear\"]\n",
    "        },\n",
    "    },\n",
    "    \"early_terminate\": {  # Stop bad runs early\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 5,\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T02:12:03.171974Z",
     "iopub.status.busy": "2025-05-13T02:12:03.171682Z",
     "iopub.status.idle": "2025-05-13T02:12:03.550870Z",
     "shell.execute_reply": "2025-05-13T02:12:03.550043Z",
     "shell.execute_reply.started": "2025-05-13T02:12:03.171953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: bvx0cfc7\n",
      "Sweep URL: https://wandb.ai/DI_725___Final_Project/Phase_2___Hyper_Parameter_Search/sweeps/bvx0cfc7\n"
     ]
    }
   ],
   "source": [
    "# Create the sweep in W&B, get its ID\n",
    "sweep_id = wandb.sweep(sweep_config,\n",
    "                      project=\"Phase_2___Hyper_Parameter_Search\",\n",
    "                      entity=\"DI_725___Final_Project\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow; text-align:center; padding:40px; font-family:sans-serif;\">\n",
    "  <h3 style=\"color:red;\"> Launch Sweep Agents :  </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train, count=100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7305746,
     "sourceId": 11642684,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 23393,
     "modelInstanceId": 37999,
     "sourceId": 45318,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
